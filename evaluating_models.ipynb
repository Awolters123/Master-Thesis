{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f484a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "from transformers import AdamWeightDecay\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "from difflib import Differ\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a2a24d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('silver_test/Multatuli_MaxHavelaar_silver.txt', 'r') as s1:\n",
    "    silver_data1 = s1.readlines()\n",
    "    \n",
    "with open('silver_test/Nescio_Titaantjes_silver.txt', 'r') as s2:\n",
    "    silver_data2 = s2.readlines()\n",
    "    \n",
    "with open('silver_test/ConanDoyle_SherlockHolmesDeAgraSchat_silver.txt', 'r') as s3:\n",
    "    silver_data3 = s3.readlines()\n",
    "    \n",
    "with open('new_gold/Multatuli_MaxHavelaar_gold.txt', 'r') as g1:\n",
    "    gold_data1 = g1.readlines()\n",
    "    \n",
    "with open('new_gold/Nescio_Titaantjes_gold.txt', 'r') as g2:\n",
    "    gold_data2 = g2.readlines()\n",
    "    \n",
    "with open('new_gold/ConanDoyle_SherlockHolmesDeAgraSchat_gold.txt', 'r') as g3:\n",
    "    gold_data3 = g3.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f217100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_set, model, tok):\n",
    "    tokenized = tok(test_set, max_length=155, padding=True, truncation=True, return_tensors='tf')\n",
    "    out = model.generate(**tokenized, max_length=250)\n",
    "\n",
    "    pred = []\n",
    "    for n in out:\n",
    "        pred.append(tok.decode(n, text_target=True, skip_special_tokens=True))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "38890788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sent(data, max_length):\n",
    "    short_sent = []\n",
    "    long_sent = []\n",
    "    for n in data:\n",
    "        n = n.split('|')\n",
    "        if len(n[1]) <= max_length:\n",
    "            short_sent.append(n[1])\n",
    "        elif len(n[1]) > max_length:\n",
    "            n[1] = re.sub(r'(\\s)+(?=[^[]*?\\])', '@@', n[1])\n",
    "            n[1] = n[1].replace(\"] [\", \"]##[\")\n",
    "            lines = textwrap.wrap(n[1], max_length, break_long_words=False)\n",
    "            long_sent.append(lines)\n",
    "\n",
    "    new_data = []\n",
    "    for s in long_sent:\n",
    "        for s1 in s:\n",
    "            s1 = s1.replace(']##[', '] [')\n",
    "            s1 = re.sub(r'(@@)+(?=[^[]*?\\])', ' ', s1)\n",
    "            new_data.append(s1)\n",
    "\n",
    "    for x in short_sent:\n",
    "        new_data.append(x)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f4227338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(data):\n",
    "    source_text = []\n",
    "    target_text = []\n",
    "    for d in data:\n",
    "        d = d.split('|')\n",
    "        x = d[1]\n",
    "        source = []\n",
    "        target = []\n",
    "        spel = re.findall(r'\\[.*?\\]', x)\n",
    "        if spel:\n",
    "            for s in spel:\n",
    "                s = s.split()\n",
    "                if s[1] == '@alt':\n",
    "                    target.append(''.join(s[2:3]))\n",
    "                    source.append(''.join(s[3:-1]))\n",
    "                elif s[1] == '@mwu_alt':\n",
    "                    target.append(''.join(s[2:3]))\n",
    "                    source.append(''.join(s[3:-1]).replace('-', ''))\n",
    "                elif s[1] == '@mwu':\n",
    "                    target.append(''.join(s[2:-1]))\n",
    "                    source.append(' '.join(s[2:-1]))\n",
    "                elif s[1] == '@postag':\n",
    "                    target.append(''.join(s[-2]))\n",
    "                    source.append(''.join(s[-2]))\n",
    "                elif s[1] == '@phantom':\n",
    "                    target.append(''.join(s[2]))\n",
    "                    source.append('')\n",
    "\n",
    "        target2 = []\n",
    "        for t in target:\n",
    "            if t[0] == '~':\n",
    "                t = t.split('~')\n",
    "                target2.append(t[1])\n",
    "            else:\n",
    "                target2.append(t)\n",
    "\n",
    "        sent = re.sub(r'\\[.*?\\]', 'EMPTY', x)\n",
    "        word_c = 0\n",
    "        src = []\n",
    "        trg = []\n",
    "        for word in sent.split():\n",
    "            if word == 'EMPTY':\n",
    "                src.append(source[word_c])\n",
    "                trg.append(target2[word_c])\n",
    "                word_c += 1\n",
    "            else:\n",
    "                src.append(word)\n",
    "                trg.append(word)\n",
    "        source_text.append(' '.join(src))\n",
    "        target_text.append(' '.join(trg))\n",
    "    return source_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "19a82283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sent(pred, gold):\n",
    "    predv1 = []\n",
    "    goldv1 = []\n",
    "\n",
    "    d = Differ()\n",
    "    diff = list(d.compare(pred, gold))\n",
    "    for l, n in enumerate(diff):\n",
    "        n = n.strip()\n",
    "        if n[0] == '-' and len(n) > 1:\n",
    "            predv1.append(n)\n",
    "        elif n[0] == '+':\n",
    "            goldv1.append(n)\n",
    "        elif n[0] != '?':\n",
    "            goldv1.append(n)\n",
    "            predv1.append(n)\n",
    "    \n",
    "    for lp, p in enumerate(predv1):\n",
    "        p = p.strip()\n",
    "        next_p = predv1[(lp+1)%(len(predv1))]\n",
    "        next_pp = predv1[(lp+2)%(len(predv1))]\n",
    "        if p[0] == '-' and next_p[0] == '-' and next_pp[0] == '-':\n",
    "            predv1.remove(p)\n",
    "            predv1.remove(next_p)\n",
    "            predv1.remove(next_pp)\n",
    "            predv1.insert(lp, p + ' ' + next_p + ' ' + next_pp)\n",
    "                \n",
    "    for lp, p in enumerate(predv1):\n",
    "        p = p.strip()\n",
    "        next_p = predv1[(lp+1)%(len(predv1))]\n",
    "        if p[0] == '-' and next_p[0] == '-':\n",
    "            predv1.remove(p)\n",
    "            predv1.remove(next_p)\n",
    "            predv1.insert(lp, p + ' ' + next_p)\n",
    "        \n",
    "    for lg, g in enumerate(goldv1):\n",
    "        g = g.strip()\n",
    "        next_g = goldv1[(lg+1)%(len(goldv1))]\n",
    "        next_gg = goldv1[(lg+2)%(len(goldv1))]\n",
    "        if g[0] == '+' and next_g[0] == '+' and next_gg[0] == '+':\n",
    "            goldv1.remove(g)\n",
    "            goldv1.remove(next_g)\n",
    "            goldv1.remove(next_gg)\n",
    "            goldv1.insert(lg, g + ' ' + next_g + ' ' + next_gg)\n",
    "            \n",
    "    for lg, g in enumerate(goldv1):\n",
    "        g = g.strip()\n",
    "        next_g = goldv1[(lg+1)%(len(goldv1))]\n",
    "        if g[0] == '+' and next_g[0] == '+':\n",
    "            goldv1.remove(g)\n",
    "            goldv1.remove(next_g)\n",
    "            goldv1.insert(lg, g + ' ' + next_g)\n",
    "            \n",
    "    predv2 = []\n",
    "    for pred1 in predv1:\n",
    "        pred1 = pred1.replace('-', ' ').strip()\n",
    "        predv2.append(pred1)\n",
    "        \n",
    "    goldv2 = []\n",
    "    for gold1 in goldv1:\n",
    "        gold1 = gold1.replace('+', ' ').strip()\n",
    "        goldv2.append(gold1)\n",
    "            \n",
    "    return predv2, goldv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "458d6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_err(raw, gold, pred):\n",
    "    cor = 0\n",
    "    changed = 0\n",
    "    total = 0\n",
    "\n",
    "    if len(gold) != len(pred):\n",
    "        return 'Error: gold normalization contains a different numer of sentences(' + str(len(gold)) + ') compared to system output(' + str(len(pred)) + ')'\n",
    "       \n",
    "    for sentRaw, sentGold, sentPred in zip(raw, gold, pred):\n",
    "        if len(sentGold) != len(sentPred):\n",
    "            return 'Error: a sentence has a different length in you output, check the order of the sentences'\n",
    "        for wordRaw, wordGold, wordPred in zip(sentRaw, sentGold, sentPred):\n",
    "            if wordRaw != wordGold:\n",
    "                changed += 1\n",
    "            if wordGold == wordPred:\n",
    "                cor += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = float(cor) / total\n",
    "    lai = float(total - changed) / total\n",
    "    err = float(accuracy - lai) / (1-lai)\n",
    "    return 'Baseline Accuracy: {:.2f}%\\nAccuracy: {:.2f}%\\nError Reduction Rate: {:.2f}%'.format((lai * 100), (accuracy * 100), (err * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a1dda983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pre_rec(gold, pred):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    if len(gold) != len(pred):\n",
    "        return 'Error: gold normalization contains a different numer of sentences(' + str(len(gold)) + ') compared to system output(' + str(len(pred)) + ')'\n",
    "       \n",
    "    for sentGold, sentPred in zip(gold, pred):\n",
    "        if len(sentGold) == len(sentPred):\n",
    "            if len(sentGold) > 0:\n",
    "                pre_rec = precision_recall_fscore_support(sentGold, sentPred, average='macro', zero_division=True)\n",
    "                precision.append(pre_rec[0])\n",
    "                recall.append(pre_rec[1])\n",
    "    \n",
    "    avg_pre = round(sum(precision) / len(precision), 4)\n",
    "    avg_rec = round(sum(recall) / len(recall), 4)\n",
    "    return 'Avg Precision: {:.2f}%\\nAvg Recall: {:.2f}%'.format((avg_pre * 100), (avg_rec * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f8a480f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rulebased(gold_data, silver_data, verbose=False):\n",
    "    source_gold, target_gold = create_data(gold_data)\n",
    "    source_silver, target_silver = create_data(silver_data)\n",
    "    \n",
    "    pred = []\n",
    "    gold = []\n",
    "    raw = []\n",
    "    for r, p, g in zip(source_gold, target_silver, target_gold):\n",
    "        r1 = r.split()\n",
    "        p1 = p.split() \n",
    "        g1 = g.split() \n",
    "        if len(p1) == len(g1) and len(r1) == len(g1):\n",
    "            raw.append(r1)\n",
    "            pred.append(p1)\n",
    "            gold.append(g1)\n",
    "        elif len(p1) != len(g1):\n",
    "            p1, g1 = align_sent(p1, g1)\n",
    "            if len(p1) == len(g1):\n",
    "                raw.append(r1)\n",
    "                pred.append(p1)\n",
    "                gold.append(g1)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('ORIG:\\t', len(r1), r1)\n",
    "                    print('PRED:\\t', len(p1), p1)\n",
    "                    print('GOLD:\\t', len(g1), g1)\n",
    "                    print('\\n')  \n",
    "    print(evaluate_err(raw, gold, pred))\n",
    "    print(evaluate_pre_rec(gold, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "844890e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_T5(original, predictions, gold_set, verbose=False):\n",
    "    test_pred = []\n",
    "    test_gold = []\n",
    "    test_orig = []\n",
    "    for orig, pred, gold in zip(original, predictions, gold_set):\n",
    "        pred = pred.replace('!', ' !').replace('?', ' ?')\n",
    "        pred = re.sub(r'(?<=[a-zA-Z])([,])', ' ,', pred)\n",
    "        gold = gold.replace(\" 'm\", \"'m\").replace(\" 's\", \"'s\")\n",
    "        orig = orig.replace(\" 'm\", \"'m\").replace(\" 's\", \"'s\")\n",
    "        \n",
    "        pred = pred.split()\n",
    "        gold = gold.split()\n",
    "        orig = orig.split()\n",
    "        \n",
    "        if len(orig) != len(gold):\n",
    "            orig, gold = align_sent(orig, gold)\n",
    "    \n",
    "        word_exc = ['No.', 'enz.', 'Mr.', 'S.', 'D.', 'A.', 'P.', 'I.', 'X.']\n",
    "        predv1 = []\n",
    "        for p in pred:\n",
    "            p = p.strip()\n",
    "            if p not in word_exc:\n",
    "                if p[-1] == '.' and p[-2:-1] != '.':\n",
    "                    p = p[:-1] + ' ' + '.'\n",
    "                    predv1.append(p)\n",
    "                elif p[-1] == '.' and p[-2:-1] == '.' and p[-3:-2] == '.':\n",
    "                    p = p[:-3] + ' ' + '...'\n",
    "                    predv1.append(p)\n",
    "                elif p[-1] == '.' and p[-2:-1] == '.':\n",
    "                    p = p[:-2] + ' ' + '..'\n",
    "                    predv1.append(p)\n",
    "                else:\n",
    "                    predv1.append(p)\n",
    "            else:\n",
    "                predv1.append(p)\n",
    "            \n",
    "        predv2 = ' '.join(predv1).split()\n",
    "    \n",
    "        if len(predv2) == len(gold) and len(orig) == len(gold):\n",
    "            test_pred.append(predv2)\n",
    "            test_gold.append(gold)\n",
    "            test_orig.append(orig)\n",
    "        elif len(predv2) != len(gold):\n",
    "            if len(gold) > 1 and len(predv2) > 1:\n",
    "                predv2, gold = align_sent(predv2, gold)\n",
    "                if len(predv2) == len(gold):\n",
    "                    test_pred.append(predv2)\n",
    "                    test_gold.append(gold)\n",
    "                    test_orig.append(orig)\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(len(orig), orig)\n",
    "                        print(len(predv2), predv2)\n",
    "                        print(len(gold), gold)\n",
    "                        print('\\n')\n",
    "            else: \n",
    "                if verbose:\n",
    "                    print(len(orig), orig)\n",
    "                    print(len(predv2), predv2)\n",
    "                    print(len(gold), gold)\n",
    "                    print('\\n')\n",
    "                    \n",
    "    print('{}/{} ({:.2f}%) sentences are evaluated from prediction set'\n",
    "          .format(len(test_pred), len(predictions), (len(test_pred) / len(predictions) * 100)))\n",
    "    print(evaluate_err(test_orig, test_gold, test_pred))\n",
    "    print(evaluate_pre_rec(test_gold, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa64f67",
   "metadata": {},
   "source": [
    "## Testing ByT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"google/byt5-small\")\n",
    "model.load_weights('ByT5_small_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06012811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multatuli MaxHavelaar (ByT5)\n",
      "755/764 (98.82%) sentences are evaluated from prediction set\n",
      "Baseline Accuracy: 96.02%\n",
      "Accuracy: 98.67%\n",
      "Error Reduction Rate: 66.50%\n",
      "Avg Precision: 98.47%\n",
      "Avg Recall: 98.47%\n"
     ]
    }
   ],
   "source": [
    "print('Multatuli MaxHavelaar (ByT5)')\n",
    "gold1_split = split_sent(gold_data1, 150)\n",
    "source_data1, target_data1 = create_data(gold1_split) \n",
    "predictions1 = model_predict(source_data1, model, tokenizer)\n",
    "evaluate_T5(source_data1, predictions1, target_data1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "681ef346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nescio Titaantjes (ByT5)\n",
      "878/883 (99.43%) sentences are evaluated from prediction set\n",
      "Baseline Accuracy: 95.87%\n",
      "Accuracy: 99.11%\n",
      "Error Reduction Rate: 78.38%\n",
      "Avg Precision: 98.87%\n",
      "Avg Recall: 98.87%\n"
     ]
    }
   ],
   "source": [
    "print('Nescio Titaantjes (ByT5)')\n",
    "gold2_split = split_sent(gold_data2, 150)\n",
    "source_data2, target_data2 = create_data(gold2_split) \n",
    "predictions2 = model_predict(source_data2, model, tokenizer)\n",
    "evaluate_T5(source_data2, predictions2, target_data2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1476fb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConanDoyle Sherlock Holmes De Agra Schat (ByT5)\n",
      "688/690 (99.71%) sentences are evaluated from prediction set\n",
      "Baseline Accuracy: 94.29%\n",
      "Accuracy: 98.35%\n",
      "Error Reduction Rate: 71.08%\n",
      "Avg Precision: 98.22%\n",
      "Avg Recall: 98.24%\n"
     ]
    }
   ],
   "source": [
    "print('ConanDoyle Sherlock Holmes De Agra Schat (ByT5)')\n",
    "gold3_split = split_sent(gold_data3, 150)\n",
    "source_data3, target_data3 = create_data(gold3_split) \n",
    "predictions3 = model_predict(source_data3, model, tokenizer)\n",
    "evaluate_T5(source_data3, predictions3, target_data3, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b363ee4",
   "metadata": {
    "id": "IT7A3PNJbkwn"
   },
   "source": [
    "## Testing Flan-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f8bfc",
   "metadata": {
    "id": "asWrnpPmgi9h"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "model.load_weights('FlanT5_small_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15e36e0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ60RaXfaJw3",
    "outputId": "afb5ebd6-5006-4680-87fe-81551f2da2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multatuli MaxHavelaar (ByT5)\n",
      "762/764 (99.74%) sentences are evaluated from prediction set\n",
      "Baseline Accuracy: 96.00%\n",
      "Accuracy: 97.96%\n",
      "Error Reduction Rate: 48.87%\n",
      "Avg Precision: 97.91%\n",
      "Avg Recall: 97.91%\n"
     ]
    }
   ],
   "source": [
    "print('Multatuli MaxHavelaar (ByT5)')\n",
    "gold1_split = split_sent(gold_data1, 150)\n",
    "source_data1, target_data1 = create_data(gold1_split) \n",
    "predictions1 = model_predict(source_data1, model, tokenizer)\n",
    "evaluate_T5(source_data1, predictions1, target_data1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3a3cbf0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCLRszWlarDu",
    "outputId": "73412c21-f6d6-4995-ad3c-657715850923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nescio Titaantjes (ByT5)\n",
      "872/883 (98.75%) sentences are evaluated from prediction set\n",
      "Baseline Accuracy: 95.62%\n",
      "Accuracy: 97.93%\n",
      "Error Reduction Rate: 52.77%\n",
      "Avg Precision: 98.04%\n",
      "Avg Recall: 98.05%\n"
     ]
    }
   ],
   "source": [
    "print('Nescio Titaantjes (ByT5)')\n",
    "gold2_split = split_sent(gold_data2, 150)\n",
    "source_data2, target_data2 = create_data(gold2_split) \n",
    "predictions2 = model_predict(source_data2, model, tokenizer)\n",
    "evaluate_T5(source_data2, predictions2, target_data2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2acb451a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiH6hExMavqx",
    "outputId": "186aa427-beaa-43ae-bd6f-3a93a93e6f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConanDoyle Sherlock Holmes De Agra Schat (ByT5)\n",
      "686/690 (99.42%) sentences are evaluated from prediction set\n",
      "Baseline Accuracy: 94.31%\n",
      "Accuracy: 97.10%\n",
      "Error Reduction Rate: 48.93%\n",
      "Avg Precision: 96.87%\n",
      "Avg Recall: 96.89%\n"
     ]
    }
   ],
   "source": [
    "print('ConanDoyle Sherlock Holmes De Agra Schat (ByT5)')\n",
    "gold3_split = split_sent(gold_data3, 150)\n",
    "source_data3, target_data3 = create_data(gold3_split) \n",
    "predictions3 = model_predict(source_data3, model, tokenizer)\n",
    "evaluate_T5(source_data3, predictions3, target_data3, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fda3d7",
   "metadata": {},
   "source": [
    "## Testing Rule-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26ecce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multatuli MaxHavelaar (Rule-Based)\n",
      "Baseline Accuracy: 96.04%\n",
      "Accuracy: 98.81%\n",
      "Error Reduction Rate: 69.87%\n",
      "Avg Precision: 98.93%\n",
      "Avg Recall: 98.92%\n"
     ]
    }
   ],
   "source": [
    "print('Multatuli MaxHavelaar (Rule-Based)')\n",
    "evaluate_rulebased(gold_data1, silver_data1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "14c005ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nescio Titaantjes (Rule-Based)\n",
      "Baseline Accuracy: 96.30%\n",
      "Accuracy: 98.68%\n",
      "Error Reduction Rate: 64.45%\n",
      "Avg Precision: 98.88%\n",
      "Avg Recall: 98.87%\n"
     ]
    }
   ],
   "source": [
    "print('Nescio Titaantjes (Rule-Based)')\n",
    "evaluate_rulebased(gold_data2, silver_data2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "15180810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConanDoyle Sherlock Holmes De Agra Schat (Rule-Based)\n",
      "Baseline Accuracy: 94.83%\n",
      "Accuracy: 98.38%\n",
      "Error Reduction Rate: 68.60%\n",
      "Avg Precision: 98.32%\n",
      "Avg Recall: 98.35%\n"
     ]
    }
   ],
   "source": [
    "print('ConanDoyle Sherlock Holmes De Agra Schat (Rule-Based)')\n",
    "evaluate_rulebased(gold_data3, silver_data3, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
